{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 pyltp\n",
    "pyltp 是 LTP 的 Python 封装，提供了分词，词性标注，命名实体识别，依存句法分析，语义角色标注的功能。\n",
    "https://pyltp.readthedocs.io/zh_CN/latest/api.html  \n",
    "https://github.com/HIT-SCIR/pyltp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元芳你怎么看？\n",
      "我就趴窗口上看呗！\n"
     ]
    }
   ],
   "source": [
    "from pyltp import SentenceSplitter\n",
    "sents = SentenceSplitter.split('元芳你怎么看？我就趴窗口上看呗！')  # 分句\n",
    "print ('\\n'.join(sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词¶\n",
    "使用 pyltp 进行分词示例如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元芳\t你\t怎么\t看\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "LTP_DATA_DIR = '/home/ian/code/data/ltp_data_v3.4.0'  # ltp模型目录的路径\n",
    "cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')  # 分词模型路径，模型名称为`cws.model`\n",
    "\n",
    "from pyltp import Segmentor\n",
    "segmentor = Segmentor()  # 初始化实例\n",
    "segmentor.load(cws_model_path)  # 加载模型\n",
    "words = segmentor.segment('元芳你怎么看')  # 分词\n",
    "print ('\\t'.join(words))\n",
    "segmentor.release()  # 释放模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words = segmentor.segment('元芳你怎么看') 的返回值类型是native的VectorOfString类型，可以使用list转换成Python的列表类型，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyltp.VectorOfString"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['元芳', '你', '怎么', '看']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.585 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['元芳', '你', '怎么', '看']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.lcut('元芳你怎么看')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用分词外部词典\n",
    "pyltp 分词支持用户使用自定义词典。分词外部词典本身是一个文本文件（plain text），每行指定一个词，编码同样须为 UTF-8，样例如下所示\n",
    "\n",
    "------------------\n",
    "苯并芘  \n",
    "亚硝酸盐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "LTP_DATA_DIR = '/home/ian/code/data/ltp_data_v3.4.0'  # ltp模型目录的路径\n",
    "cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')  # 分词模型路径，模型名称为`cws.model`\n",
    "\n",
    "from pyltp import Segmentor\n",
    "segmentor = Segmentor()  # 初始化实例\n",
    "segmentor.load(cws_model_path)  # 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "亚硝酸盐\t是\t一\t种\t化学\t物质\n"
     ]
    }
   ],
   "source": [
    "words = segmentor.segment('亚硝酸盐是一种化学物质')\n",
    "print ('\\t'.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "亚硝酸盐\t是\t一\t种\t化学\t物质\n"
     ]
    }
   ],
   "source": [
    "segmentor.load_with_lexicon(cws_model_path, '/home/ian/code/data/ltp_data_v3.4.0/dicttest.txt') # 加载模型，第二个参数是您的外部词典文件路径\n",
    "words = segmentor.segment('亚硝酸盐是一种化学物质')\n",
    "print ('\\t'.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"一种\"都不能看成一个词。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "狗\t是\t一\t种\t动物\n"
     ]
    }
   ],
   "source": [
    "words = segmentor.segment('狗是一种动物')\n",
    "print ('\\t'.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "在外部词典里加入\"一种\"结果还是分不成一个词。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "亚硝酸盐\t是\t一\t种\t化学\t物质\n"
     ]
    }
   ],
   "source": [
    "segmentor.load_with_lexicon(cws_model_path, '/home/ian/code/data/ltp_data_v3.4.0/dicttest1.txt') # 加载模型，第二个参数是您的外部词典文件路径\n",
    "words = segmentor.segment('亚硝酸盐是一种化学物质')\n",
    "print ('\\t'.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还是jieba靠谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['亚硝酸盐', '是', '一种', '化学物质']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.lcut('亚硝酸盐是一种化学物质')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词性标注\n",
    "使用 pyltp 进行词性标注示例如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nh\tr\tr\tv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "LTP_DATA_DIR = '/home/ian/code/data/ltp_data_v3.4.0'  # ltp模型目录的路径\n",
    "pos_model_path = os.path.join(LTP_DATA_DIR, 'pos.model')  # 词性标注模型路径，模型名称为`pos.model`\n",
    "\n",
    "from pyltp import Postagger\n",
    "postagger = Postagger() # 初始化实例\n",
    "postagger.load(pos_model_path)  # 加载模型\n",
    "\n",
    "words = ['元芳', '你', '怎么', '看']  # 分词结果\n",
    "postags = postagger.postag(words)  # 词性标注\n",
    "\n",
    "print ('\\t'.join(postags))\n",
    "postagger.release()  # 释放模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依存句法分析\n",
    "使用 pyltp 进行依存句法分析示例如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4:SBV\t4:SBV\t4:ADV\t0:HED\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "LTP_DATA_DIR = '/home/ian/code/data/ltp_data_v3.4.0'  # ltp模型目录的路径\n",
    "par_model_path = os.path.join(LTP_DATA_DIR, 'parser.model')  # 依存句法分析模型路径，模型名称为`parser.model`\n",
    "\n",
    "from pyltp import Parser\n",
    "parser = Parser() # 初始化实例\n",
    "parser.load(par_model_path)  # 加载模型\n",
    "\n",
    "words = ['元芳', '你', '怎么', '看']\n",
    "postags = ['nh', 'r', 'r', 'v']\n",
    "arcs = parser.parse(words, postags)  # 句法分析\n",
    "\n",
    "print (\"\\t\".join(\"%d:%s\" % (arc.head, arc.relation) for arc in arcs))\n",
    "parser.release()  # 释放模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
